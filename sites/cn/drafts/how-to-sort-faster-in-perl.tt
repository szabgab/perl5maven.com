=title How to sort faster in Perl?
=timestamp 2012-12-11T11:45:57
=indexes map, sort, Schwartzian
=status show
=author szabgab
=index 1
=archive 1
=feed 1
=comments 1
=social 1


=abstract start

即便是一个很长的文件列表，如果以ASCII表的顺序按名字排序也会很快处理完.

然而，如果你需要根据文件大小排序的话会慢很多.

=abstract end

<h2>根据文件名排序</h2>


下面简化的示例代码创建了一个xml文件的列表，并根据文件名以字母顺序排序. 处理速度很快.

<code lang="perl">

#!/usr/bin/perl
use strict;
use warnings;

my @files = glob "*.xml";

my @sorted_files = sort @files;
</code>

<h2>根据文件名长度排序</h2>

<code lang="perl">
my @sorted_length = sort { length($a) <=> length($b) } @files;
</code>

对于3000个文件，这比根据ASCII名字排序速度要慢3倍，但是仍然很快.

<h2>根据文件大小排序</h2>

当尝试根据文件大小对3000个文件排序的时候，发现它竟然比以ACSII码排序的例子慢80倍!

<code lang="perl">
my @sort_size = sort { -s $a <=> -s $b } @files;
</code>

这说来也并不奇怪. 第一个例子中, Perl仅仅比较了数值. 第二个例子中, Perl还要在比较之前计算字符串长度.
而在第三个例子中, 每次比较之前都要到硬盘中获取两个文件的大小.

访问磁盘要远比访问内存慢的多.

问题是, <b>如何来提升这个速度?</b>.

访问磁盘的问题被排序的工作方式给放大了.

目前有很多排序算法(<a href="http://en.wikipedia.org/wiki/Quicksort">快速排序</a>,
<a href="http://en.wikipedia.org/wiki/Bubblesort">冒泡排序</a>,
<a href="http://en.wikipedia.org/wiki/Mergesort">归并排序</a>, etc.)
根据输入的不同, 有的快些，有的慢些. Perl曾经使用快速排序, 
之后换成了归并排序. 今天，如果你需要的话, 可以通过<a href="http://perldoc.perl.org/sort.html">sort</a>
指令选择排序方式.

无论你选择那一种，平均来看，至少需要N*log(N)比较. 这就意味着，对于N = 1000个文件, perl需要访问2 * 1000 * 3 = 6000次磁盘.
(两倍于比较次数.) 对每个文件, perl要获取6次大小! 这明显是很大的浪费.

我们不能避免访问磁盘来获取文件大小，我们也不能减少比较次数，但是，我们可以减少访问磁盘的次数.

<h2>预先获取文件大小</h2>

我们会预先获取所有文件大小，把它们存在内存, 然后对内存中的数据排序.

<code lang="perl">
my @unsorted_pairs = map  { [$_, -s $_] } @files;
my @sorted_pairs   = sort { $a->[1] <=> $b->[1] } @unsorted_pairs;
my @quickly_sorted_files = map  { $_->[0] } @sorted_pairs;
</code>

This might look a bit more complicated than what you'd write, but bare with me.
It will be used in a more simple way.

There are 3 steps here. In the first step we go over the list of files and for each file
we create an ARRAY reference. In the array reference we have two elements. The first one is
the name of the file, the second one is the size of the file. This will access the disk once
for every file.

In the second step, we sort the array of the small array references. When comparing two of those
small array references we fetch the element [1] of each one of them, and compare those values.
The result is another array of small array references.

In the third step we throw away the sizes and build a list of the filenames only.
What we originally wanted.


<h2>Schwartzian transform</h2>

For the above code we used 2 temporary array, that are not really necessary.
We could create a single statement that will do all the work. For this we
need to reverse the order of the statements as "data flows from right to left"
in Perl, but if we put each statement on its own line, and if we leave enough
space around the curly braces, we can have a readable piece of code.

<code lang="perl">
my @quickly_sorted_files =
    map  { $_->[0] }
    sort { $a->[1] <=> $b->[1] }
    map  { [$_, -s $_] }
    @files;
</code>

This is called the <a href="http://en.wikipedia.org/wiki/Schwartzian_transform">Schwartzian transform</a>
named after <a href="http://en.wikipedia.org/wiki/Randal_L._Schwartz">Randal L. Schwartz</a>.

When seen in code, it can be easily recognized by the map-sort-map construct.

It can be used for sorting anything, but it is especially useful when the
computation of the values to be compared is relatively heavy.

<code lang="perl">
my @sorted =
    map  { $_->[0] }
    sort { $a->[1] <=> $b->[1] }
    map  { [$_, f($_)] }
    @unsorted;
</code>


Using this algorithm for sorting the 3000 xml files the sorting became "only" 10 times slower than the
ASCII sort which means it is about 8 times faster than the code we had at the beginning.


<h2>Conclusion</h2>

Effectively we gain speed and pay by higher memory usage and code complexity.
For small arrays it is not worth it, and for large arrays it is only worth if
this change has a real impact on your program.

If the whole sorting takes up 1 second from a script that runs for 10 minutes,
then probably it is not worth the investment. On the other hand if the sorting
is a larger part of the total run-time, you should probably use the Schwartzian
transformation.

In order to find out which is the case, use <a href="https://metacpan.org/module/Devel::NYTProf">Devel::NYTProf to
profile</a> your code.

(Thanks to <a href="http://twitter.com/Smylers2">Smylers</a> for reviewing the article.)
